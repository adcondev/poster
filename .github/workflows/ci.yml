name: CI

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
    types: [ opened, synchronize, reopened ]

env:
  GO_VERSION: '1.24'

permissions:
  contents: read
  pull-requests: write
  checks: write
  security-events: write

jobs:
  pr-validation:
    name: PR Validation
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - name: Checkout code
        uses: actions/checkout@v6
        with:
          fetch-depth: 0

      - name: Validate PR Title
        uses: amannn/action-semantic-pull-request@v6
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          types: |
            feat
            fix
            docs
            style
            refactor
            perf
            test
            build
            ci
            chore
            deps
            revert
          # TODO: Reduce amount of scopes if necessary
          scopes: |
            composer
            connection
            commands
            document
            graphics
            profile
            service
            barcode
            bitimage
            character
            linespacing
            mechanismcontrol
            print
            printposition
            qrcode
            common
            models
            github
            gomod
            npm
            gh-actions
            poster
            tables
            security
            miscellaneous
            executor
            builder
            constants
            emulator
          # Please ensure your PR titles follow the "<type>(<scope>): <subject>" format.
          requireScope: true
          subjectPattern: ^(?![A-Z]).+$
          subjectPatternError: |
            The subject must start with lowercase letter.

  test-coverage:
    name: Test and Coverage
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ ubuntu-latest, windows-latest, macos-latest ]
      fail-fast: false

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Setup Go
        uses: actions/setup-go@v6
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true

      - name: Run tests with race detection
        shell: bash
        run: go test -v -race -coverprofile=coverage.txt -covermode=atomic ./pkg/...

      - name: Generate coverage report
        if: matrix.os == 'ubuntu-latest'
        run: |
          go tool cover -func=coverage.txt -o=coverage-summary.txt
          echo "## üìä Test Coverage Summary" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          tail -n 1 coverage-summary.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Upload coverage to Codecov
        if: matrix.os == 'ubuntu-latest'
        uses: codecov/codecov-action@v5
        with:
          files: ./coverage.txt
          fail_ci_if_error: false
          flags: unittests

  benchmark:
    name: ‚ö° Performance Benchmarks
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    permissions:
      pull-requests: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v6
        with:
          fetch-depth: 0

      - name: Setup Go ${{ env.GO_VERSION }}
        uses: actions/setup-go@v6
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true

      - name: Run benchmarks (base)
        run: |
          git checkout ${{ github.event.pull_request.base.sha }}
          if ! go test -bench=. -benchmem -run=^$ ./... > /tmp/base-benchmark.txt 2>&1; then
            echo "‚ö†Ô∏è Warning: Base branch benchmarks failed. This is non-critical." >&2
            echo "Error details:" >&2
            cat /tmp/base-benchmark.txt >&2
            # Create empty file to indicate failure but continue
            echo "# Base benchmark execution failed" > /tmp/base-benchmark.txt
          fi

      - name: Run benchmarks (current)
        run: |
          git checkout ${{ github.event.pull_request.head.sha }}
          if ! go test -bench=. -benchmem -run=^$ ./... > /tmp/current-benchmark.txt 2>&1; then
            echo "‚ùå Error: Current branch benchmarks failed." >&2
            echo "Error details:" >&2
            cat /tmp/current-benchmark.txt >&2
            echo "Benchmark execution failed. Please fix the errors above." >&2
            exit 1
          fi
          # Verify benchmarks were actually found
          if ! grep -q "^Benchmark" /tmp/current-benchmark.txt; then
            echo "‚ö†Ô∏è Warning: No benchmarks found in current branch test output."
            echo "This may indicate that no benchmark tests exist or they were not executed."
            # Create a minimal report
            echo "No benchmarks found" > /tmp/current-benchmark.txt
          fi

      - name: Compare benchmarks
        id: compare
        run: |
          cat > compare.sh << 'EOFSCRIPT'
          #!/bin/bash
          
          echo "## ‚ö° Benchmark Results"
          echo ""
          echo "### üìà Performance Comparison"
          echo ""
          
          # Check if benchmarks exist
          if ! grep -q "^Benchmark" /tmp/current-benchmark.txt; then
            echo "‚ö†Ô∏è No benchmarks found in current branch"
            exit 0
          fi
          
          echo "<details>"
          echo "<summary>üìä Click to expand detailed results</summary>"
          echo ""
          echo "#### Current Branch Results"
          echo '```'
          grep "^Benchmark" /tmp/current-benchmark.txt | head -20
          echo '```'
          echo ""
          
          if [ -f /tmp/base-benchmark.txt ] && grep -q "^Benchmark" /tmp/base-benchmark.txt; then
            echo "#### Base Branch Results"
            echo '```'
            grep "^Benchmark" /tmp/base-benchmark.txt | head -20
            echo '```'
            echo ""
            echo "üí° **Note:** Use \`benchstat\` for statistical comparison"
          elif [ -f /tmp/base-benchmark.txt ] && grep -q "# Base benchmark execution failed" /tmp/base-benchmark.txt; then
            echo "#### ‚ö†Ô∏è Base Branch Benchmarks Failed"
            echo ""
            echo "The base branch benchmarks could not be executed (possibly due to compilation errors)."
            echo "Comparison with base branch is not available."
          fi
          
          echo "</details>"
          echo ""
          echo "### üéØ Summary"
          
          BENCH_COUNT=$(grep -c "^Benchmark" /tmp/current-benchmark.txt)
          echo "- **Total Benchmarks:** $BENCH_COUNT"
          
          # Extract performance metrics
          if grep -q "ns/op" /tmp/current-benchmark.txt; then
            AVG_NS=$(grep "ns/op" /tmp/current-benchmark.txt | awk '{sum+=$3; count++} END {if(count>0) print int(sum/count); else print "N/A"}')
            echo "- **Average Speed:** ${AVG_NS} ns/op"
          fi
          
          if grep -q "B/op" /tmp/current-benchmark.txt; then
            AVG_MEM=$(grep "B/op" /tmp/current-benchmark.txt | awk '{sum+=$5; count++} END {if(count>0) print int(sum/count); else print "N/A"}')
            echo "- **Average Memory:** ${AVG_MEM} B/op"
          fi
          
          if grep -q "allocs/op" /tmp/current-benchmark.txt; then
            AVG_ALLOCS=$(grep "allocs/op" /tmp/current-benchmark.txt | awk '{sum+=$7; count++} END {if(count>0) print int(sum/count); else print "N/A"}')
            echo "- **Average Allocations:** ${AVG_ALLOCS} allocs/op"
          fi
          EOFSCRIPT
          
          chmod +x compare.sh
          ./compare.sh > benchmark-comment.md

      - name: Post benchmark results to PR
        uses: actions/github-script@v8
        with:
          script: |
            const fs = require('fs');
            const comment = fs.readFileSync('benchmark-comment.md', 'utf8');
            
            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(c => 
              c.user.type === 'Bot' && 
              c.body.includes('‚ö° Benchmark Results')
            );
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

      - name: Add to job summary
        run: cat benchmark-comment.md >> $GITHUB_STEP_SUMMARY

  security:
    name: üîí Security Scan
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: Upload results to GitHub Security
        uses: github/codeql-action/upload-sarif@v4
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  lint:
    name: üîç Linting
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Setup Go ${{ env.GO_VERSION }}
        uses: actions/setup-go@v6
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true

      - name: Run golangci-lint
        uses: golangci/golangci-lint-action@v9
        with:
          version: latest
          args: --config=.golangci.yml --timeout=5m